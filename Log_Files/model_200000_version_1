Initializing the doom.
Doom is initialized.
2019-02-01 08:31:52.910363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:04:00.0
totalMemory: 10.73GiB freeMemory: 10.29GiB
2019-02-01 08:31:52.910407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-01 08:31:53.281823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-01 08:31:53.281871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-01 08:31:53.281878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-01 08:31:53.282140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9930 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
Starting training.
Steps: 2000/200000 Episodes: 8 Rewards: mean: 0.50, std: 0.50, min: 0.00, max: 1.00
Steps: 4000/200000 Episodes: 10 Rewards: mean: 0.80, std: 0.40, min: 0.00, max: 1.00
Steps: 6000/200000 Episodes: 9 Rewards: mean: 0.89, std: 0.31, min: 0.00, max: 1.00
Steps: 8000/200000 Episodes: 9 Rewards: mean: 0.78, std: 0.42, min: 0.00, max: 1.00
Steps: 10000/200000 Episodes: 10 Rewards: mean: 0.90, std: 0.30, min: 0.00, max: 1.00
Steps: 12000/200000 Episodes: 9 Rewards: mean: 0.89, std: 0.31, min: 0.00, max: 1.00
Steps: 14000/200000 Episodes: 10 Rewards: mean: 0.80, std: 0.40, min: 0.00, max: 1.00
Steps: 16000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 18000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 20000/200000 Episodes: 11 Rewards: mean: 0.91, std: 0.29, min: 0.00, max: 1.00
Steps: 22000/200000 Episodes: 8 Rewards: mean: 0.88, std: 0.33, min: 0.00, max: 1.00
Steps: 24000/200000 Episodes: 10 Rewards: mean: 0.70, std: 0.46, min: 0.00, max: 1.00
Steps: 26000/200000 Episodes: 11 Rewards: mean: 0.82, std: 0.39, min: 0.00, max: 1.00
Steps: 28000/200000 Episodes: 6 Rewards: mean: 0.50, std: 0.50, min: 0.00, max: 1.00
Steps: 30000/200000 Episodes: 9 Rewards: mean: 0.56, std: 0.50, min: 0.00, max: 1.00
Steps: 32000/200000 Episodes: 7 Rewards: mean: 0.86, std: 0.35, min: 0.00, max: 1.00
Steps: 34000/200000 Episodes: 12 Rewards: mean: 0.83, std: 0.37, min: 0.00, max: 1.00
Steps: 36000/200000 Episodes: 17 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 38000/200000 Episodes: 16 Rewards: mean: 0.94, std: 0.24, min: 0.00, max: 1.00
Steps: 40000/200000 Episodes: 10 Rewards: mean: 0.80, std: 0.40, min: 0.00, max: 1.00
Steps: 42000/200000 Episodes: 11 Rewards: mean: 0.73, std: 0.45, min: 0.00, max: 1.00
Steps: 44000/200000 Episodes: 10 Rewards: mean: 0.80, std: 0.40, min: 0.00, max: 1.00
Steps: 46000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 48000/200000 Episodes: 23 Rewards: mean: 0.96, std: 0.20, min: 0.00, max: 1.00
Steps: 50000/200000 Episodes: 20 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 52000/200000 Episodes: 26 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 54000/200000 Episodes: 18 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 56000/200000 Episodes: 8 Rewards: mean: 0.75, std: 0.43, min: 0.00, max: 1.00
Steps: 58000/200000 Episodes: 8 Rewards: mean: 0.75, std: 0.43, min: 0.00, max: 1.00
Steps: 60000/200000 Episodes: 11 Rewards: mean: 0.73, std: 0.45, min: 0.00, max: 1.00
Steps: 62000/200000 Episodes: 11 Rewards: mean: 0.82, std: 0.39, min: 0.00, max: 1.00
Steps: 64000/200000 Episodes: 12 Rewards: mean: 0.83, std: 0.37, min: 0.00, max: 1.00
Steps: 66000/200000 Episodes: 11 Rewards: mean: 0.82, std: 0.39, min: 0.00, max: 1.00
Steps: 68000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 70000/200000 Episodes: 7 Rewards: mean: 0.57, std: 0.49, min: 0.00, max: 1.00
Steps: 72000/200000 Episodes: 7 Rewards: mean: 0.71, std: 0.45, min: 0.00, max: 1.00
Steps: 74000/200000 Episodes: 6 Rewards: mean: 0.17, std: 0.37, min: 0.00, max: 1.00
Steps: 76000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 78000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 80000/200000 Episodes: 8 Rewards: mean: 0.50, std: 0.50, min: 0.00, max: 1.00
Steps: 82000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 84000/200000 Episodes: 5 Rewards: mean: 0.20, std: 0.40, min: 0.00, max: 1.00
Steps: 86000/200000 Episodes: 6 Rewards: mean: 0.17, std: 0.37, min: 0.00, max: 1.00
Steps: 88000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 90000/200000 Episodes: 5 Rewards: mean: 0.40, std: 0.49, min: 0.00, max: 1.00
Steps: 92000/200000 Episodes: 5 Rewards: mean: 0.00, std: 0.00, min: 0.00, max: 0.00
Steps: 94000/200000 Episodes: 7 Rewards: mean: 0.29, std: 0.45, min: 0.00, max: 1.00
Steps: 96000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 98000/200000 Episodes: 6 Rewards: mean: 0.33, std: 0.47, min: 0.00, max: 1.00
Steps: 100000/200000 Episodes: 7 Rewards: mean: 0.29, std: 0.45, min: 0.00, max: 1.00
Steps: 102000/200000 Episodes: 6 Rewards: mean: 0.33, std: 0.47, min: 0.00, max: 1.00
Steps: 104000/200000 Episodes: 7 Rewards: mean: 0.29, std: 0.45, min: 0.00, max: 1.00
Steps: 106000/200000 Episodes: 6 Rewards: mean: 0.33, std: 0.47, min: 0.00, max: 1.00
Steps: 108000/200000 Episodes: 8 Rewards: mean: 0.62, std: 0.48, min: 0.00, max: 1.00
Steps: 110000/200000 Episodes: 7 Rewards: mean: 0.57, std: 0.49, min: 0.00, max: 1.00
Steps: 112000/200000 Episodes: 9 Rewards: mean: 0.78, std: 0.42, min: 0.00, max: 1.00
Steps: 114000/200000 Episodes: 8 Rewards: mean: 0.75, std: 0.43, min: 0.00, max: 1.00
Steps: 116000/200000 Episodes: 6 Rewards: mean: 0.33, std: 0.47, min: 0.00, max: 1.00
Steps: 118000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 120000/200000 Episodes: 13 Rewards: mean: 0.85, std: 0.36, min: 0.00, max: 1.00
Steps: 122000/200000 Episodes: 6 Rewards: mean: 0.67, std: 0.47, min: 0.00, max: 1.00
Steps: 124000/200000 Episodes: 9 Rewards: mean: 0.67, std: 0.47, min: 0.00, max: 1.00
Steps: 126000/200000 Episodes: 8 Rewards: mean: 0.38, std: 0.48, min: 0.00, max: 1.00
Steps: 128000/200000 Episodes: 5 Rewards: mean: 0.40, std: 0.49, min: 0.00, max: 1.00
Steps: 130000/200000 Episodes: 6 Rewards: mean: 0.33, std: 0.47, min: 0.00, max: 1.00
Steps: 132000/200000 Episodes: 9 Rewards: mean: 0.56, std: 0.50, min: 0.00, max: 1.00
Steps: 134000/200000 Episodes: 7 Rewards: mean: 0.43, std: 0.49, min: 0.00, max: 1.00
Steps: 136000/200000 Episodes: 11 Rewards: mean: 0.73, std: 0.45, min: 0.00, max: 1.00
Steps: 138000/200000 Episodes: 13 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 140000/200000 Episodes: 12 Rewards: mean: 0.75, std: 0.43, min: 0.00, max: 1.00
Steps: 142000/200000 Episodes: 13 Rewards: mean: 0.85, std: 0.36, min: 0.00, max: 1.00
Steps: 144000/200000 Episodes: 10 Rewards: mean: 0.70, std: 0.46, min: 0.00, max: 1.00
Steps: 146000/200000 Episodes: 16 Rewards: mean: 0.94, std: 0.24, min: 0.00, max: 1.00
Steps: 148000/200000 Episodes: 14 Rewards: mean: 0.93, std: 0.26, min: 0.00, max: 1.00
Steps: 150000/200000 Episodes: 16 Rewards: mean: 0.94, std: 0.24, min: 0.00, max: 1.00
Steps: 152000/200000 Episodes: 24 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 154000/200000 Episodes: 17 Rewards: mean: 0.88, std: 0.32, min: 0.00, max: 1.00
Steps: 156000/200000 Episodes: 19 Rewards: mean: 0.95, std: 0.22, min: 0.00, max: 1.00
Steps: 158000/200000 Episodes: 11 Rewards: mean: 0.82, std: 0.39, min: 0.00, max: 1.00
Steps: 160000/200000 Episodes: 18 Rewards: mean: 0.94, std: 0.23, min: 0.00, max: 1.00
Steps: 162000/200000 Episodes: 19 Rewards: mean: 0.95, std: 0.22, min: 0.00, max: 1.00
Steps: 164000/200000 Episodes: 16 Rewards: mean: 0.94, std: 0.24, min: 0.00, max: 1.00
Steps: 166000/200000 Episodes: 13 Rewards: mean: 0.85, std: 0.36, min: 0.00, max: 1.00
Steps: 168000/200000 Episodes: 17 Rewards: mean: 0.82, std: 0.38, min: 0.00, max: 1.00
Steps: 170000/200000 Episodes: 9 Rewards: mean: 0.67, std: 0.47, min: 0.00, max: 1.00
Steps: 172000/200000 Episodes: 19 Rewards: mean: 0.89, std: 0.31, min: 0.00, max: 1.00
Steps: 174000/200000 Episodes: 13 Rewards: mean: 0.85, std: 0.36, min: 0.00, max: 1.00
Steps: 176000/200000 Episodes: 25 Rewards: mean: 0.96, std: 0.20, min: 0.00, max: 1.00
Steps: 178000/200000 Episodes: 13 Rewards: mean: 1.00, std: 0.00, min: 1.00, max: 1.00
Steps: 180000/200000 Episodes: 14 Rewards: mean: 0.93, std: 0.26, min: 0.00, max: 1.00
Steps: 182000/200000 Episodes: 11 Rewards: mean: 0.82, std: 0.39, min: 0.00, max: 1.00
Steps: 184000/200000 Episodes: 15 Rewards: mean: 0.87, std: 0.34, min: 0.00, max: 1.00
Steps: 186000/200000 Episodes: 13 Rewards: mean: 0.85, std: 0.36, min: 0.00, max: 1.00
Steps: 188000/200000 Episodes: 16 Rewards: mean: 0.88, std: 0.33, min: 0.00, max: 1.00
Steps: 190000/200000 Episodes: 14 Rewards: mean: 0.93, std: 0.26, min: 0.00, max: 1.00
Steps: 192000/200000 Episodes: 13 Rewards: mean: 0.92, std: 0.27, min: 0.00, max: 1.00
Steps: 194000/200000 Episodes: 15 Rewards: mean: 0.87, std: 0.34, min: 0.00, max: 1.00
Steps: 196000/200000 Episodes: 17 Rewards: mean: 0.88, std: 0.32, min: 0.00, max: 1.00
Steps: 198000/200000 Episodes: 10 Rewards: mean: 0.90, std: 0.30, min: 0.00, max: 1.00
Steps: 200000/200000 Episodes: 19 Rewards: mean: 0.89, std: 0.31, min: 0.00, max: 1.00
Training Scores [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Running Experiment Number 1
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 0.0
Total reward: 1.0
Total reward: 0.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 0.0
********************
Running Experiment Number 2
Total reward: 1.0
Total reward: 0.0
Total reward: 0.0
Total reward: 1.0
Total reward: 0.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 0.0
Total reward: 1.0
********************
Running Experiment Number 3
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 0.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
Total reward: 1.0
********************
[[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]
Mean Reward [1.         0.66666667 0.66666667 0.33333333 0.66666667 0.66666667
 1.         1.         0.66666667 0.66666667]
Std Reward [0.         0.47140452 0.47140452 0.47140452 0.47140452 0.47140452
 0.         0.         0.47140452 0.47140452]
